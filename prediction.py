# -*- coding: utf-8 -*-
"""HR_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sR_zhYnsTFNxamME_QNMEMdG9fLkUNly

# Proyek Akhir: Menyelesaikan Permasalahan Perusahaan Edutech

- Nama: Achmad Fauzihan Bagus Sajiwo
- Email: achmadfauzihanbagussajiwo@gmail.com
- Id Dicoding: A296YBF008

## Persiapan

### Menyiapkan library yang dibutuhkan
"""

import pandas as pd
import numpy as np
import seaborn as sns
import tensorflow as tf
import warnings
import joblib

import matplotlib.pyplot as plt

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier

warnings.filterwarnings("ignore")

"""### Menyiapkan data yang akan diguankan"""

pd.set_option('display.max_columns', None)

employee = pd.read_csv('employee_data.csv')

"""## Data Understanding"""

employee.head()

employee.info()

employee.describe(include='all')

"""## Data Visualitation"""

# Mengubah 1.0 ke 'Yes' dan 0.0 ke 'No'
employee['Attrition'] = employee['Attrition'].replace({1.0: 'Yes', 0.0: 'No'})

fig, axes = plt.subplots(1, 3, figsize=(10, 5))

# Pie chart pertama: Attrition
attr_counts = employee['Attrition'].value_counts()
axes[0].pie(attr_counts, autopct='%1.1f%%', labels=['No', 'Yes'])
axes[0].set_title('Attrition %')

# Pie chart kedua: Gender
gndr_counts = employee['Gender'].value_counts()
axes[1].pie(gndr_counts, autopct='%1.1f%%', labels=['Male', 'Female'])
axes[1].set_title('Gender %')

# Pie chart ketiga: Department
dept_counts = employee['Department'].value_counts()
axes[2].pie(dept_counts, autopct='%1.1f%%', labels=['R&D', 'Sales', 'HR'])
axes[2].set_title('Department %')

# Menampilkan plot
plt.tight_layout()
plt.show()

fig, ax = plt.subplots(figsize = (8,6))
counts, edges, bars = ax.hist(employee['Age'])
plt.ylabel('Number of Employees')
plt.xlabel('Age')
plt.title('Histogram of Age')
plt.bar_label(bars)

plt.show()

fig, ax = plt.subplots(figsize = (8,6))
counts, edges, bars = ax.hist(employee['MonthlyIncome'])
plt.ylabel('# of Employees')
plt.xlabel('Monthly Income')
plt.title('Histogram of Monthly Income')
plt.bar_label(bars)

plt.show()

"""## Data Preparation / Preprocessing"""

employee.isna().sum()

employee = employee.dropna()

employee['Attrition'] = employee.Attrition.astype("category").cat.codes

employee = employee.drop(columns=['StandardHours','EmployeeCount','Over18','StockOptionLevel'])

categorical_col = []
for column in employee.columns:
    if employee[column].dtype == object and len(employee[column].unique()) <= 50:
        categorical_col.append(column)

# Menampilkan beberapa isi dari kolom-kolom kategori
for col in categorical_col:
    print(f"Kolom: {col}")
    print(employee[col].unique())  # Menampilkan nilai unik
    print("-" * 40)

"""### Encoding"""

label = LabelEncoder()
for column in categorical_col:
    employee[column] = label.fit_transform(employee[column])

"""### Data Splitting"""

X = employee.drop('Attrition', axis=1)
y = employee.Attrition

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""## Modeling

### KNN
"""

knn = KNeighborsClassifier()
knn.fit(X_train, y_train)

knn_acc = accuracy_score(y_test, knn.predict(X_test))

print("Train set Accuracy:"+str(accuracy_score(y_train, knn.predict(X_train))*100))
print("Test Set Accuracy:"+str(accuracy_score(y_test, knn.predict(X_test))*100))

"""### Random Forest"""

rf = RandomForestClassifier()
rf.fit(X_train,y_train)

rf_acc=accuracy_score(y_test,rf.predict(X_test))

print("Train Set Accuracy:"+str(accuracy_score(y_train,rf.predict(X_train))*100))
print("Test Set Accuracy:"+str(accuracy_score(y_test,rf.predict(X_test))*100))

"""### SVM"""

svm = SVC()
svm.fit(X_train, y_train)

svm_acc = accuracy_score(y_test, svm.predict(X_test))

print("Train Set Accuracy:" + str(accuracy_score(y_train, svm.predict(X_train)) * 100))
print("Test Set Accuracy:" + str(accuracy_score(y_test, svm.predict(X_test)) * 100))

"""## Evaluation"""

models = pd.DataFrame({'Model': ['KNN', 'Random Forest Classifier', 'SVC'], 'Accuracy': [ knn_acc, rf_acc, svm_acc]})

models.sort_values(by = 'Accuracy', ascending = False)

plt.figure(figsize = (8,5))
sns.barplot(x = 'Model', y = 'Accuracy', data = models)
plt.show()

"""### KNN"""

# Prediksi data test
y_pred_knn = knn.predict(X_test)

# Tampilkan classification report
print(classification_report(y_test, y_pred_knn))

"""### Random Forest"""

# Prediksi data test
y_pred_rf = rf.predict(X_test)

# Tampilkan classification report
print(classification_report(y_test, y_pred_rf))

"""### SVM"""

# Prediksi data test
y_pred_svm = svm.predict(X_test)

# Tampilkan classification report
print(classification_report(y_test, y_pred_svm))

"""## Save Model"""

# Menyimpan Model sebagai File .pkl
joblib.dump(rf, "model.pkl")

"""## Prediction"""

# Memuat model RandomForest yang sudah disimpan
rf_job = joblib.load('model.pkl')

# Prediksi pada data uji (X_test)
predicted_values = rf_job.predict(X_test)

# Ambil 5 data acak dari X_test dan y_test
random_indices = X_test.sample(n=20, random_state=42).index

# Membuat DataFrame untuk perbandingan hasil prediksi dan nilai asli
comparison_df = pd.DataFrame({
    'Actual': y_test.loc[random_indices],
    'Predicted': [predicted_values[X_test.index.get_loc(i)] for i in random_indices]
})

# Menyandikan hasil dalam bentuk 'Attrition' atau 'No Attrition'
comparison_df['Actual'] = comparison_df['Actual'].apply(lambda x: 'Attrition' if x == 1 else 'No Attrition')
comparison_df['Predicted'] = comparison_df['Predicted'].apply(lambda x: 'Attrition' if x == 1 else 'No Attrition')

# Menampilkan tabel hasil perbandingan
print(comparison_df)